{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# standard imports\n",
    "import tensorrt #For GPU\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from keras.callbacks import History\n",
    "import matplotlib.pyplot as plt\n",
    "import np_utils\n",
    "import os\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from plain_neural_network import*\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = \"/albedo/home/ssunar/CNN_eddy_detection/for_paper/interpolation/south_atlantic\"\n",
    "# input_file_paths = sorted(\n",
    "#     [\n",
    "#         os.path.join(input_dir, fname)\n",
    "#         for fname in os.listdir(input_dir)\n",
    "#     ])\n",
    "# #input_file_paths.pop(29)\n",
    "# #input_file_paths.pop(11)\n",
    "\n",
    "# data_x = xr.open_mfdataset(input_file_paths,combine = 'nested', concat_dim=\"TIME\")\n",
    "# data_x = data_x.ssh.to_numpy()\n",
    "# X = np.float32(data_x)\n",
    "                            \n",
    "# X[X>1000] = 0\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import cm\n",
    "# fig, ax = plt.subplots( 1, 1, )\n",
    "# ax.pcolormesh(data_long,data_lat,np.transpose(X[0,:,:]), cmap=cm.seismic, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = \"/albedo/home/ssunar/CNN_eddy_detection/for_paper/segmentation_masks/south_atlantic\"\n",
    "# input_file_paths = sorted(\n",
    "#     [\n",
    "#         os.path.join(input_dir, fname)\n",
    "#         for fname in os.listdir(input_dir)\n",
    "#     ])\n",
    "# #input_file_paths.pop(29)\n",
    "# #input_file_paths.pop(11)\n",
    "\n",
    "# data_y = xr.open_mfdataset(input_file_paths,combine = 'nested', concat_dim=\"TIME\")\n",
    "# data_y = data_y.seg_mask.to_numpy()\n",
    "# Y = np.float32(data_y)\n",
    "\n",
    "\n",
    "# (Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "input_dir = \"/albedo/work/user/ssunar/for_paper/segmentation_masks/south_atlantic/\"\n",
    "input_file_paths = sorted(glob.glob(input_dir+'*.nc'))\n",
    "data = xr.open_mfdataset(input_file_paths,combine = 'nested', concat_dim=\"TIME\").astype('float32')\n",
    "X = data.ssh.to_numpy()\n",
    "Y = data.seg_mask.to_numpy()\n",
    "X[X>1000] = 0\n",
    "\n",
    "X.shape\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_long = data.LONGITUDE\n",
    "data_lat = data.LATITUDE\n",
    "xx, yy = np.meshgrid(data_long, data_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "fig, ax = plt.subplots( 1, 1, )\n",
    "ax.pcolormesh(data_long,data_lat,np.transpose(X[100,:,:]), cmap=cm.seismic, vmin=-1, vmax=1)\n",
    "ax.contour(xx, yy, np.transpose(Y[100,:,:]), levels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[(Y != 1) & (Y!=2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_3d_vector(vector):\n",
    "    X, Y, Z = vector.shape\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(X):\n",
    "        vector_2d = vector[i,:,:]\n",
    "        B = Y // 256 + 1\n",
    "        for b in range(B):\n",
    "            start_y = b * 256\n",
    "            end_y = (b + 1) * 256\n",
    "            if end_y > Y:\n",
    "                start_y = Y - 256\n",
    "                end_y = Y\n",
    "      \n",
    "            C = Z // 256 + 1\n",
    "            for c in range(C):\n",
    "                start_z = c * 256\n",
    "                end_z = (c + 1) * 256\n",
    "                if end_z > Z:\n",
    "                    start_z = Z - 256\n",
    "                    end_z = Z\n",
    "                final_chunk = vector_2d[start_y:end_y, start_z:end_z]\n",
    "                chunks.append(final_chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = np.array(split_3d_vector(X))\n",
    "new_Y = np.array(split_3d_vector(Y))\n",
    "\n",
    "data_x = new_X\n",
    "data_y = new_Y\n",
    "\n",
    "(data_x.shape)\n",
    "(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (256, 256)\n",
    "num_classes = 3\n",
    "batch_size = 16\n",
    "epochs = 60\n",
    "total_samples = len(data_x)-1000\n",
    "# if len(data_x) > 4000:\n",
    "#     total_samples = 4000\n",
    "# else:\n",
    "#     total_samples = len(data_x)\n",
    "print(total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(img_size, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function \n",
    "#defined from the paper:\n",
    "#Santana et al._2020_Neural network training for the detection and classification of oceanic mesoscale eddies\n",
    "\n",
    "unique, counts = np.unique(data_y, return_counts=True)\n",
    "dict(zip(unique, counts))\n",
    "\n",
    "freq = [np.sum(counts)/j for j in counts]\n",
    "weightsSeg = [f/np.sum(freq) for f in freq]\n",
    "print(weightsSeg)\n",
    "\n",
    "def dice_coef_anti(y_true, y_pred):\n",
    "    smooth = 1.  # to avoid zero division\n",
    "    y_true_anti = y_true[:,:,1]\n",
    "    y_pred_anti = y_pred[:,:,1]\n",
    "    intersection_anti = K.sum(y_true_anti * y_pred_anti)\n",
    "    return (2 * intersection_anti + smooth) / (K.sum(y_true_anti)+ K.sum(y_pred_anti) + smooth)\n",
    "\n",
    "def dice_coef_cyc(y_true, y_pred):\n",
    "    smooth = 1.  # to avoid zero division\n",
    "    y_true_cyc = y_true[:,:,2]\n",
    "    y_pred_cyc = y_pred[:,:,2]\n",
    "    intersection_cyc = K.sum(y_true_cyc * y_pred_cyc)\n",
    "    return (2 * intersection_cyc + smooth) / (K.sum(y_true_cyc) + K.sum(y_pred_cyc) + smooth)\n",
    "\n",
    "def dice_coef_nn(y_true, y_pred):\n",
    "    smooth = 1.  # to avoid zero division\n",
    "    y_true_nn = y_true[:,:,0]\n",
    "    y_pred_nn = y_pred[:,:,0]\n",
    "    intersection_nn = K.sum(y_true_nn * y_pred_nn)\n",
    "    return (2 * intersection_nn + smooth) / (K.sum(y_true_nn) + K.sum(y_pred_nn) + smooth)\n",
    "    \n",
    "def mean_dice_coef(y_true, y_pred):\n",
    "    return (dice_coef_anti(y_true, y_pred) + dice_coef_cyc(y_true, y_pred) + dice_coef_nn(y_true, y_pred))/3.\n",
    "\n",
    "def weighted_mean_dice_coef(y_true, y_pred):\n",
    "    #return (weightsSeg[2]*dice_coef_anti(y_true, y_pred) + weightsSeg[1]*dice_coef_cyc(y_true, y_pred) + weightsSeg[0]*dice_coef_nn(y_true, y_pred))\n",
    "    return (weightsSeg[2]*dice_coef_anti(y_true, y_pred) + weightsSeg[1]*dice_coef_cyc(y_true, y_pred) + weightsSeg[0]*dice_coef_nn(y_true, y_pred))\n",
    "      \n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - weighted_mean_dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our img paths into a training and a validation set\n",
    "split = 0.3\n",
    "train_samples = int((1-split)*total_samples)\n",
    "#same seed must be used\n",
    "random.Random(0).shuffle(data_x)\n",
    "random.Random(0).shuffle(data_y)\n",
    "train_input = data_x[0:train_samples]\n",
    "train_target = data_y[0:train_samples]\n",
    "val_input = data_x[train_samples:total_samples]\n",
    "val_target = data_y[train_samples:total_samples]\n",
    "\n",
    "print(\"train_input:\", train_input.shape)\n",
    "print(\"val_input:\", val_input.shape)\n",
    "\n",
    "# Instantiate data Sequences for each split\n",
    "train_gen = plain_net_eddy(batch_size, img_size, train_input, train_target)\n",
    "val_gen = plain_net_eddy(batch_size, img_size, val_input, val_target)\n",
    "print(\"Size of each batch: \",train_gen[1][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/albedo/soft/sw/spack-sw/cuda/11.7.0-qk7q7bh/'\n",
    "os.environ['XLA_FLAGS']\n",
    "# print(os.environ.get('CUDA_HOME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_save = \"/albedo/work/user/ssunar/for_paper/unet_trained/south_atlantic/train\"\n",
    "os.makedirs(file_path_save, exist_ok=True)\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss=dice_coef_loss, metrics=['categorical_accuracy', mean_dice_coef, weighted_mean_dice_coef])\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(file_path_save, save_best_only=True , monitor='val_loss',save_weights_only=True, save_freq=\"epoch\"),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1, mode='auto', min_delta=1e-30, min_lr=1e-30)]\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch.\n",
    "history = model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks, shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(file_path_save + '/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_path = \"/albedo/work/user/ssunar/for_paper/unet_trained/south_atlantic/train\"\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.semilogy(model.history.history['loss'])\n",
    "plt.semilogy(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right');\n",
    "plt.savefig(dir_path + \"loss_graph.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "val_gen = plain_net_eddy(batch_size, img_size, val_input, val_target)\n",
    "val_preds = model.predict(val_gen)\n",
    "print(val_preds.shape)\n",
    "\n",
    "end = time.time()\n",
    "time_per_img = (end - start)/val_preds.shape[0]\n",
    "print(\"Time Per image:\",time_per_img)\n",
    "print(\"Time for 1 year eqv:\",time_per_img*365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we do not use all samples for training.\n",
    "if len(data_x) > total_samples + 1000:\n",
    "    test_size = 1000\n",
    "    test_inp = data_x[total_samples : total_samples+test_size]\n",
    "    test_seg = data_y[total_samples : total_samples+test_size]\n",
    "elif len(data_x) > total_samples:\n",
    "    test_size = len(data_x) - total_samples\n",
    "    test_inp = data_x[total_samples : total_samples+test_size]\n",
    "    test_seg = data_y[total_samples : total_samples+test_size]\n",
    "else:\n",
    "    test_inp = val_input\n",
    "    test_seg = val_target\n",
    "    test_size = len(test_inp)\n",
    "    \n",
    "test_inp.shape\n",
    "test_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert test segmentation mask into catagorical form\n",
    "categorical_test_seg = to_categorical(test_seg)\n",
    "categorical_test_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test data\n",
    "test_inp = np.reshape(test_inp,(len(test_inp),img_size[0],img_size[1],1))\n",
    "catagorical_test_preds = model.predict(test_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_inp, catagorical_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.argmax(np.reshape(catagorical_test_preds[70],(1,img_size[1],img_size[0],3)), axis=-1)\n",
    "mask = np.reshape(mask,(img_size[0],img_size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing the prediction of one image of the validation set\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(mask.T, cmap='viridis')\n",
    "plt.colorbar(extend='both', fraction=0.042, pad=0.04)\n",
    "plt.axis('off')\n",
    "plt.title('Result Segmentation');\n",
    "plt.savefig(dir_path + \"prediction.png\", dpi = 300)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(test_seg[70].T, cmap='viridis')\n",
    "plt.colorbar(extend='both', fraction=0.042, pad=0.04)\n",
    "plt.axis('off')\n",
    "plt.title('Groundtruth Segmentation');\n",
    "plt.savefig(dir_path + \"groundtruth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eddy-tracking",
   "language": "python",
   "name": "eddy-tracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
