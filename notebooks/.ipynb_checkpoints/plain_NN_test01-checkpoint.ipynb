{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /global/AWIsoft/intel-python/2020.2.902/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /global/AWIsoft/intel-python/2020.2.902/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /global/AWIsoft/intel-python/2020.2.902/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /global/AWIsoft/intel-python/2020.2.902/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /global/AWIsoft/intel-python/2020.2.902/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /global/AWIsoft/intel-python/2020.2.902/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /global/AWIsoft/intel-python/2020.2.902/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /global/AWIsoft/intel-python/2020.2.902/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "import xarray as xr\n",
    "#from keras import optimizers\n",
    "from sklearn import preprocessing\n",
    "from keras.callbacks import History\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "from plain_neural_network import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/ollie/bpanthi/nn_interpolation/ssh_gridded_1961_001_01_new.nc\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataArray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-657c896ee8f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0minput_file_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/AWIsoft/intel-python/2020.2.902/lib/python3.7/site-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    231\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise AttributeError(\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0;34m\"{!r} object has no attribute {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         )\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataArray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "input_dir = \"/work/ollie/bpanthi/nn_interpolation/\"\n",
    "input_file_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "    ])\n",
    "print(input_file_paths[0])\n",
    "data_x = xr.open_dataset(input_file_paths[0])\n",
    "data_x = data_x.ssh.to_numpy()\n",
    "data_x = np.float32(data_x)\n",
    "input_file_paths.pop(0)\n",
    "\n",
    "for abs_name in input_file_paths:\n",
    "    print(abs_name)\n",
    "    temp = xr.open_dataset(abs_name)\n",
    "    temp = temp.ssh.to_numpy()\n",
    "    temp = np.float32(temp)\n",
    "    data_x = np.concatenate((data_x, temp), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_01_new.nc\n",
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_02_new.nc\n",
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_03_new.nc\n",
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_04_new.nc\n",
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_05_new.nc\n",
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_06_new.nc\n",
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_07_new.nc\n",
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_08_new.nc\n",
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_09_new.nc\n",
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_10_new.nc\n",
      "/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_11_new.nc\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"/home/ollie/ssunar/segmentation_masks/\"\n",
    "input_file_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "    ])\n",
    "print(input_file_paths[0])\n",
    "data_y = xr.open_dataset(input_file_paths[0])\n",
    "data_y = data_y.seg_mask.to_numpy()\n",
    "data_y = np.float32(data_y)\n",
    "input_file_paths.pop(0)\n",
    "\n",
    "for abs_name in input_file_paths:\n",
    "    print(abs_name)\n",
    "    temp = xr.open_dataset(abs_name)\n",
    "    temp = temp.seg_mask.to_numpy()\n",
    "    temp = np.float32(temp)\n",
    "    data_y = np.concatenate((data_y, temp), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 1200, 480)\n",
      "(332, 1200, 480)\n"
     ]
    }
   ],
   "source": [
    "file_path_save = \"/work/ollie/bpanthi/NN_weights\"\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)\n",
    "\n",
    "img_size = (1200, 480)\n",
    "num_classes = 3\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "total_samples = len(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.0383692e-01 -6.9714171e-01 -6.9363987e-01 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]\n",
      " [-7.4457765e-01 -7.2361225e-01 -7.2052300e-01 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]\n",
      " [-7.6013374e-01 -7.4673313e-01 -7.4736404e-01 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]\n",
      " ...\n",
      " [-1.6232173e+00 -1.6178026e+00 -1.6113625e+00 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]\n",
      " [-1.6377305e+00 -1.6311280e+00 -1.6258327e+00 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]\n",
      " [-1.6477681e+00 -1.6418573e+00 -1.6364002e+00 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]]\n",
      "9.96921e+36\n",
      "-2.0459373\n"
     ]
    }
   ],
   "source": [
    "print(data_x[0])\n",
    "print(np.max(data_x))\n",
    "print(np.min(data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 480, 1)\n",
      "(1200, 480, 3)\n",
      "(1200, 480, 1)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "result = data_y[0]\n",
    "result = result[..., np.newaxis]\n",
    "print(result.shape)\n",
    "\n",
    "result_1 = np_utils.to_categorical(result)\n",
    "print(result_1.shape)\n",
    "mask = np.argmax(result_1, axis=-1)\n",
    "mask = np.expand_dims(mask, axis=-1)\n",
    "print(mask.shape)\n",
    "\n",
    "print(np.sum(result-mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7038369  -0.6971417  -0.6936399  ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.74457765 -0.72361225 -0.720523   ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.76013374 -0.7467331  -0.74736404 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-1.6232173  -1.6178026  -1.6113625  ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.6377305  -1.631128   -1.6258327  ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.6477681  -1.6418573  -1.6364002  ...  0.          0.\n",
      "   0.        ]]\n",
      "1.2572272\n",
      "-2.0459373\n",
      "516648\n",
      "28040\n",
      "31312\n"
     ]
    }
   ],
   "source": [
    "#Work on this part\n",
    "# for i in range(total_samples):\n",
    "#     data_x[i] = (2*float(data_x[i] - np.min(data_x[i])))/(np.max(data_x[i]) - np.min(data_x[i])) - 1 \n",
    "# for i in range(total_samples):\n",
    "#     scaler = preprocessing.StandardScaler().fit(data_x[i])\n",
    "#     data_x[i] = scaler.transform(data_x[i])\n",
    "data_x[data_x>1000] = 0\n",
    "print(data_x[0])\n",
    "print(np.max(data_x))\n",
    "print(np.min(data_x))\n",
    "print(np.size(data_y[0][data_y[0]==0]))\n",
    "print(np.size(data_y[0][data_y[0]==1]))\n",
    "print(np.size(data_y[0][data_y[0]==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input: (265, 1200, 480)\n",
      "val_input: (67, 1200, 480)\n"
     ]
    }
   ],
   "source": [
    "# Split our img paths into a training and a validation set\n",
    "split = 0.2\n",
    "train_samples = int((1-split)*total_samples)\n",
    "#same seed must be used\n",
    "random.Random(0).shuffle(data_x)\n",
    "random.Random(0).shuffle(data_y)\n",
    "train_input = data_x[0:train_samples]\n",
    "train_target = data_y[0:train_samples]\n",
    "val_input = data_x[train_samples:total_samples]\n",
    "val_target = data_y[train_samples:total_samples]\n",
    "\n",
    "print(\"train_input:\", train_input.shape)\n",
    "print(\"val_input:\", val_input.shape)\n",
    "#print(train_target[0][200])\n",
    "\n",
    "# Instantiate data Sequences for each split\n",
    "train_gen = plain_net_eddy(batch_size, img_size, train_input, train_target)\n",
    "val_gen = plain_net_eddy(batch_size, img_size, val_input, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 13:37:45.148861: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /global/AWIsoft/proj/4.9.3/lib:/global/AWIsoft/intel//2018/intelpython2/lib\n",
      "2022-03-25 13:37:45.148897: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-25 13:37:45.148923: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (prod-0199): /proc/driver/nvidia/version does not exist\n",
      "2022-03-25 13:37:45.149238: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1200, 480, 1)]    0         \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 1200, 480, 16)    41        \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1200, 480, 16)    64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1200, 480, 16)     0         \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separab  (None, 1200, 480, 16)    416       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1200, 480, 16)    64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1200, 480, 16)     0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 600, 240, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separab  (None, 600, 240, 16)     416       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 600, 240, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 600, 240, 16)      0         \n",
      "                                                                 \n",
      " separable_conv2d_3 (Separab  (None, 600, 240, 16)     416       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 600, 240, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 600, 240, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 300, 120, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " separable_conv2d_4 (Separab  (None, 300, 120, 16)     416       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 300, 120, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 300, 120, 16)      0         \n",
      "                                                                 \n",
      " separable_conv2d_5 (Separab  (None, 300, 120, 16)     416       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 300, 120, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 300, 120, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 150, 60, 16)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 150, 60, 16)      2320      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 150, 60, 16)      64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 150, 60, 16)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 150, 60, 16)      2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 150, 60, 16)      64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 150, 60, 16)       0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 300, 120, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 300, 120, 16)     2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 300, 120, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 300, 120, 16)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 300, 120, 16)     2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 300, 120, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 300, 120, 16)      0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 600, 240, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 600, 240, 16)     2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 600, 240, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 600, 240, 16)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 600, 240, 16)     2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 600, 240, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 600, 240, 16)      0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 1200, 480, 16)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 1200, 480, 8)     1160      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 1200, 480, 8)      0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_12 (Bat  (None, 1200, 480, 8)     32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1200, 480, 3)      219       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,220\n",
      "Trainable params: 17,820\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(img_size, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Work on this part\n",
    "from keras import backend as K\n",
    "smooth = 1.  # to avoid zero division\n",
    "\n",
    "def dice_coef_anti(y_true, y_pred):\n",
    "    y_true_anti = (y_true[:,:,1])\n",
    "    y_pred_anti = (y_pred[:,:,1])\n",
    "    intersection_anti = K.sum(y_true_anti) * (y_pred_anti)\n",
    "    return (2 * intersection_anti + smooth) / (K.sum(y_true_anti)+ K.sum(y_pred_anti) + smooth)\n",
    "\n",
    "def dice_coef_cyc(y_true, y_pred):\n",
    "    y_true_cyc = (y_true[:,:,2])\n",
    "    y_pred_cyc = (y_pred[:,:,2])\n",
    "    intersection_cyc = K.sum(y_true_cyc * y_pred_cyc)\n",
    "    return (2 * intersection_cyc + smooth) / (K.sum(y_true_cyc) + K.sum(y_pred_cyc) + smooth)\n",
    "\n",
    "def dice_coef_nn(y_true, y_pred):\n",
    "    y_true_nn = (y_true[:,:,0])\n",
    "    y_pred_nn = (y_pred[:,:,0])\n",
    "    intersection_nn = K.sum(y_true_nn * y_pred_nn)\n",
    "    return (2 * intersection_nn + smooth) / (K.sum(y_true_nn) + K.sum(y_pred_nn) + smooth)\n",
    "    \n",
    "def mean_dice_coef(y_true, y_pred):\n",
    "    return (dice_coef_anti(y_true, y_pred) + dice_coef_cyc(y_true, y_pred) + dice_coef_nn(y_true, y_pred))/3.\n",
    "\n",
    "def weighted_mean_dice_coef(y_true, y_pred):\n",
    "    return (0.36*dice_coef_anti(y_true, y_pred) + 0.62*dice_coef_cyc(y_true, y_pred) + 0.02*dice_coef_nn(y_true, y_pred))\n",
    "  \n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - weighted_mean_dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3560 - categorical_accuracy: 0.3585 - mean_dice_coef: 0.6461 - weighted_mean_dice_coef: 0.6440"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 13:39:23.234928: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /work/ollie/bpanthi/NN_weights/assets\n",
      "16/16 [==============================] - 100s 6s/step - loss: 0.3560 - categorical_accuracy: 0.3585 - mean_dice_coef: 0.6461 - weighted_mean_dice_coef: 0.6440 - val_loss: 0.6734 - val_categorical_accuracy: 0.0515 - val_mean_dice_coef: 0.3288 - val_weighted_mean_dice_coef: 0.3266 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 93s 6s/step - loss: 0.2709 - categorical_accuracy: 0.3283 - mean_dice_coef: 0.7560 - weighted_mean_dice_coef: 0.7291 - val_loss: 0.6823 - val_categorical_accuracy: 0.0515 - val_mean_dice_coef: 0.3217 - val_weighted_mean_dice_coef: 0.3177 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 92s 6s/step - loss: 0.2705 - categorical_accuracy: 0.3269 - mean_dice_coef: 0.7596 - weighted_mean_dice_coef: 0.7295 - val_loss: 0.6808 - val_categorical_accuracy: 0.0503 - val_mean_dice_coef: 0.3231 - val_weighted_mean_dice_coef: 0.3192 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2705 - categorical_accuracy: 0.3249 - mean_dice_coef: 0.7602 - weighted_mean_dice_coef: 0.7295INFO:tensorflow:Assets written to: /work/ollie/bpanthi/NN_weights/assets\n",
      "16/16 [==============================] - 97s 6s/step - loss: 0.2705 - categorical_accuracy: 0.3249 - mean_dice_coef: 0.7602 - weighted_mean_dice_coef: 0.7295 - val_loss: 0.6725 - val_categorical_accuracy: 0.0503 - val_mean_dice_coef: 0.3304 - val_weighted_mean_dice_coef: 0.3275 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2704 - categorical_accuracy: 0.3228 - mean_dice_coef: 0.7605 - weighted_mean_dice_coef: 0.7296INFO:tensorflow:Assets written to: /work/ollie/bpanthi/NN_weights/assets\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.2704 - categorical_accuracy: 0.3228 - mean_dice_coef: 0.7605 - weighted_mean_dice_coef: 0.7296 - val_loss: 0.6589 - val_categorical_accuracy: 0.0543 - val_mean_dice_coef: 0.3420 - val_weighted_mean_dice_coef: 0.3411 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2704 - categorical_accuracy: 0.3208 - mean_dice_coef: 0.7607 - weighted_mean_dice_coef: 0.7296INFO:tensorflow:Assets written to: /work/ollie/bpanthi/NN_weights/assets\n",
      "16/16 [==============================] - 97s 6s/step - loss: 0.2704 - categorical_accuracy: 0.3208 - mean_dice_coef: 0.7607 - weighted_mean_dice_coef: 0.7296 - val_loss: 0.6396 - val_categorical_accuracy: 0.0563 - val_mean_dice_coef: 0.3580 - val_weighted_mean_dice_coef: 0.3604 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "11/16 [===================>..........] - ETA: 26s - loss: 0.2701 - categorical_accuracy: 0.3193 - mean_dice_coef: 0.7609 - weighted_mean_dice_coef: 0.7299"
     ]
    }
   ],
   "source": [
    "#optimizer = keras.optimizers.Adam(clipvalue=0.5)\n",
    "model.compile(optimizer=\"adam\", loss=dice_coef_loss, metrics=['categorical_accuracy', mean_dice_coef, weighted_mean_dice_coef])\n",
    "#model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "#model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(file_path_save, save_best_only=True , monitor='val_loss'),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, mode='auto', min_delta=1e-30, min_lr=1e-30)]\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch.\n",
    "history = model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.semilogy(history.history['loss'])\n",
    "plt.semilogy(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = plain_net_eddy(batch_size, img_size, val_input, val_target)\n",
    "val_preds = model.predict(val_gen)\n",
    "print(val_preds.shape)\n",
    "print(val_preds[0][0][0])\n",
    "print(val_preds[0][10][10])\n",
    "print(val_preds[0][100][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing the prediction of first image of the validation set\n",
    "%matplotlib inline\n",
    "mask = np.argmax(val_preds[0], axis=-1)\n",
    "mask = np.expand_dims(mask, axis=-1)\n",
    "result = mask[:, :, 0]\n",
    "result = result.T\n",
    "\n",
    "#print(result[np.where[result==0]])\n",
    "\n",
    "dct = {0: 255., 1: 0., 2: 50.}\n",
    "n = [[dct[i] for i in j] for j in result]\n",
    "\n",
    "plt.imshow(n, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
