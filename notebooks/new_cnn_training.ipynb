{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 20:10:26.226187: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# standard imports\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from keras.callbacks import History\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from plain_neural_network import*\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(365, 840, 480)\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"/albedo/home/ssunar/CNN_eddy_detection/for_paper/interpolation/south_atlantic/months\"\n",
    "input_file_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "    ])\n",
    "#input_file_paths.pop(29)\n",
    "#input_file_paths.pop(11)\n",
    "\n",
    "data_x = xr.open_mfdataset(input_file_paths,combine = 'nested', concat_dim=\"TIME\")\n",
    "data_x = data_x.ssh.to_numpy()\n",
    "X = np.float32(data_x)\n",
    "                            \n",
    "X[X>1000] = 0\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 840, 480)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = \"/albedo/home/ssunar/CNN_eddy_detection/for_paper/segmentation_masks/south_atlantic\"\n",
    "input_file_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "    ])\n",
    "#input_file_paths.pop(29)\n",
    "#input_file_paths.pop(11)\n",
    "\n",
    "data_y = xr.open_mfdataset(input_file_paths,combine = 'nested', concat_dim=\"TIME\")\n",
    "data_y = data_y.seg_mask.to_numpy()\n",
    "Y = np.float32(data_y)\n",
    "\n",
    "\n",
    "(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[(Y != 1) & (Y!=2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_3d_vector(vector):\n",
    "    X, Y, Z = vector.shape\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(X):\n",
    "        vector_2d = vector[i,:,:]\n",
    "        B = Y // 256 + 1\n",
    "        for b in range(B):\n",
    "            start_y = b * 256\n",
    "            end_y = (b + 1) * 256\n",
    "            if end_y > Y:\n",
    "                start_y = Y - 256\n",
    "                end_y = Y\n",
    "      \n",
    "            C = Z // 256 + 1\n",
    "            for c in range(C):\n",
    "                start_z = c * 256\n",
    "                end_z = (c + 1) * 256\n",
    "                if end_z > Z:\n",
    "                    start_z = Z - 256\n",
    "                    end_z = Z\n",
    "                final_chunk = vector_2d[start_y:end_y, start_z:end_z]\n",
    "                chunks.append(final_chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2920, 256, 256)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2920, 256, 256)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X = np.array(split_3d_vector(X))\n",
    "(new_X.shape)\n",
    "\n",
    "new_Y = np.array(split_3d_vector(Y))\n",
    "(new_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_x_1 = data_x\\ndata_y_1 = data_y\\n\\n#only using a portion of data from this region\\nused_split = 0.4\\nused_samples = int(used_split*len(data_x))\\n#same seed must be used\\nrandom.Random(0).shuffle(data_x)\\nrandom.Random(0).shuffle(data_y)\\ndata_x_1 = data_x[0:used_samples]\\ndata_y_1 = data_y[0:used_samples]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data_x_1 = data_x\n",
    "data_y_1 = data_y\n",
    "\n",
    "#only using a portion of data from this region\n",
    "used_split = 0.4\n",
    "used_samples = int(used_split*len(data_x))\n",
    "#same seed must be used\n",
    "random.Random(0).shuffle(data_x)\n",
    "random.Random(0).shuffle(data_y)\n",
    "data_x_1 = data_x[0:used_samples]\n",
    "data_y_1 = data_y[0:used_samples]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput_dir = \"/work/ollie/bpanthi/NN_gulf/\"\\ninput_file_paths = sorted(\\n    [\\n        os.path.join(input_dir, fname)\\n        for fname in os.listdir(input_dir)\\n    ])\\ninput_file_paths.pop(6)\\ndata_x_2 = xr.open_mfdataset(input_file_paths,combine = \\'nested\\', concat_dim=\"TIME\")\\ndata_x_2 = data_x_2.ssh.to_numpy()\\ndata_x_2 = np.float32(data_x_2)\\n                            \\ndata_x_2[data_x_2>1000] = 0\\ndata_x_2 = data_x_2[:,52:308, 52:308]\\nprint(data_x_2.shape)\\n\\ninput_dir = \"/home/ollie/ssunar/segmentation_masks_NN_gulf\"\\ninput_file_paths = sorted(\\n    [\\n        os.path.join(input_dir, fname)\\n        for fname in os.listdir(input_dir)\\n    ])\\ninput_file_paths.pop(6)\\ndata_y_2 = xr.open_mfdataset(input_file_paths,combine = \\'nested\\', concat_dim=\"TIME\")\\ndata_y_2 = data_y_2.seg_mask.to_numpy()\\ndata_y_2 = np.float32(data_y_2)\\ndata_y_2 = data_y_2[:,52:308, 52:308]\\nprint(data_y_2.shape)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "input_dir = \"/work/ollie/bpanthi/NN_gulf/\"\n",
    "input_file_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "    ])\n",
    "input_file_paths.pop(6)\n",
    "data_x_2 = xr.open_mfdataset(input_file_paths,combine = 'nested', concat_dim=\"TIME\")\n",
    "data_x_2 = data_x_2.ssh.to_numpy()\n",
    "data_x_2 = np.float32(data_x_2)\n",
    "                            \n",
    "data_x_2[data_x_2>1000] = 0\n",
    "data_x_2 = data_x_2[:,52:308, 52:308]\n",
    "print(data_x_2.shape)\n",
    "\n",
    "input_dir = \"/home/ollie/ssunar/segmentation_masks_NN_gulf\"\n",
    "input_file_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "    ])\n",
    "input_file_paths.pop(6)\n",
    "data_y_2 = xr.open_mfdataset(input_file_paths,combine = 'nested', concat_dim=\"TIME\")\n",
    "data_y_2 = data_y_2.seg_mask.to_numpy()\n",
    "data_y_2 = np.float32(data_y_2)\n",
    "data_y_2 = data_y_2[:,52:308, 52:308]\n",
    "print(data_y_2.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput_dir = \"/work/ollie/bpanthi/NN_kursaal/\"\\ninput_file_paths = sorted(\\n    [\\n        os.path.join(input_dir, fname)\\n        for fname in os.listdir(input_dir)\\n    ])\\n\\ndata_x_3 = xr.open_mfdataset(input_file_paths,combine = \\'nested\\', concat_dim=\"TIME\")\\ndata_x_3 = data_x_3.ssh.to_numpy()\\ndata_x_3 = np.float32(data_x_3)\\n                            \\ndata_x_3[data_x_3>1000] = 0\\ndata_x_3 = data_x_3[:,52:308, 52:308]\\nprint(data_x_3.shape)\\n\\ninput_dir = \"/home/ollie/ssunar/segmentation_masks_NN_kursaal\"\\ninput_file_paths = sorted(\\n    [\\n        os.path.join(input_dir, fname)\\n        for fname in os.listdir(input_dir)\\n    ])\\ndata_y_3 = xr.open_mfdataset(input_file_paths,combine = \\'nested\\', concat_dim=\"TIME\")\\ndata_y_3 = data_y_3.seg_mask.to_numpy()\\ndata_y_3 = np.float32(data_y_3)\\ndata_y_3 = data_y_3[:,52:308, 52:308]\\nprint(data_y_3.shape)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "input_dir = \"/work/ollie/bpanthi/NN_kursaal/\"\n",
    "input_file_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "    ])\n",
    "\n",
    "data_x_3 = xr.open_mfdataset(input_file_paths,combine = 'nested', concat_dim=\"TIME\")\n",
    "data_x_3 = data_x_3.ssh.to_numpy()\n",
    "data_x_3 = np.float32(data_x_3)\n",
    "                            \n",
    "data_x_3[data_x_3>1000] = 0\n",
    "data_x_3 = data_x_3[:,52:308, 52:308]\n",
    "print(data_x_3.shape)\n",
    "\n",
    "input_dir = \"/home/ollie/ssunar/segmentation_masks_NN_kursaal\"\n",
    "input_file_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "    ])\n",
    "data_y_3 = xr.open_mfdataset(input_file_paths,combine = 'nested', concat_dim=\"TIME\")\n",
    "data_y_3 = data_y_3.seg_mask.to_numpy()\n",
    "data_y_3 = np.float32(data_y_3)\n",
    "data_y_3 = data_y_3[:,52:308, 52:308]\n",
    "print(data_y_3.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_x = np.concatenate((data_x_1, np.concatenate((data_x_2,data_x_3), axis=0)), axis=0)\\ndata_y = np.concatenate((data_y_1, np.concatenate((data_y_2,data_y_3), axis=0)), axis=0)\\nprint(data_x.shape)\\nprint(data_y.shape)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data_x = np.concatenate((data_x_1, np.concatenate((data_x_2,data_x_3), axis=0)), axis=0)\n",
    "data_y = np.concatenate((data_y_1, np.concatenate((data_y_2,data_y_3), axis=0)), axis=0)\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2190\n"
     ]
    }
   ],
   "source": [
    "img_size = (256, 256)\n",
    "num_classes = 3\n",
    "batch_size = 16\n",
    "epochs = 90\n",
    "total_samples = len(data_x)\n",
    "print(total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 20:51:03.812220: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " separable_conv2d (SeparableCon  (None, 256, 256, 16  25         ['input_1[0][0]']                \n",
      " v2D)                           )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 16  64         ['separable_conv2d[0][0]']       \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 256, 16  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_1 (SeparableC  (None, 256, 256, 16  400        ['activation[0][0]']             \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 16  64         ['separable_conv2d_1[0][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 256, 256, 16  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256, 256, 16  0           ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 16  0           ['dropout[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_2 (SeparableC  (None, 128, 128, 16  400        ['max_pooling2d[0][0]']          \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 16  64         ['separable_conv2d_2[0][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 128, 128, 16  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (SeparableC  (None, 128, 128, 16  400        ['activation_2[0][0]']           \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 16  64         ['separable_conv2d_3[0][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128, 128, 16  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128, 128, 16  0           ['activation_3[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)  0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " separable_conv2d_4 (SeparableC  (None, 64, 64, 32)  656         ['max_pooling2d_1[0][0]']        \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 32)  128         ['separable_conv2d_4[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_5 (SeparableC  (None, 64, 64, 32)  1312        ['activation_4[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 32)  128         ['separable_conv2d_5[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64, 64, 32)   0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)  0           ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " separable_conv2d_6 (SeparableC  (None, 32, 32, 32)  1312        ['max_pooling2d_2[0][0]']        \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 32)  128         ['separable_conv2d_6[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 32)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_7 (SeparableC  (None, 32, 32, 32)  1312        ['activation_6[0][0]']           \n",
      " onv2D)                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 32)  128         ['separable_conv2d_7[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 32, 32, 32)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 32, 32, 32)   0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 64, 64, 32)   0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 64)   0           ['up_sampling2d[0][0]',          \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " separable_conv2d_8 (SeparableC  (None, 64, 64, 32)  2624        ['concatenate[0][0]']            \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 64, 32)  128         ['separable_conv2d_8[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_9 (SeparableC  (None, 64, 64, 32)  1312        ['activation_8[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 64, 64, 32)  128         ['separable_conv2d_9[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64, 64, 32)   0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 32  0          ['dropout_4[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 48  0           ['up_sampling2d_1[0][0]',        \n",
      "                                )                                 'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " separable_conv2d_10 (Separable  (None, 128, 128, 16  1200       ['concatenate_1[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 128, 128, 16  64         ['separable_conv2d_10[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 128, 128, 16  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_11 (Separable  (None, 128, 128, 16  400        ['activation_10[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 128, 128, 16  64         ['separable_conv2d_11[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 128, 128, 16  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 128, 128, 16  0           ['activation_11[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 16  0          ['dropout_5[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 32  0           ['up_sampling2d_2[0][0]',        \n",
      "                                )                                 'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " separable_conv2d_12 (Separable  (None, 256, 256, 16  800        ['concatenate_2[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 256, 256, 16  64         ['separable_conv2d_12[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_13 (Separable  (None, 256, 256, 16  400        ['activation_12[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 256, 256, 16  64         ['separable_conv2d_13[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 256, 256, 16  0           ['activation_13[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_14 (Separable  (None, 256, 256, 3)  64         ['dropout_6[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 65536, 3)     0           ['separable_conv2d_14[0][0]']    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 65536, 3)     0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,897\n",
      "Trainable params: 13,257\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(img_size, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 127868244, 1.0: 7466151, 2.0: 8189445}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.029638252979173923, 0.5075963992256167, 0.4627653477952094]\n"
     ]
    }
   ],
   "source": [
    "#Loss function \n",
    "#defined from the paper:\n",
    "#Santana et al._2020_Neural network training for the detection and classification of oceanic mesoscale eddies\n",
    "\n",
    "unique, counts = np.unique(data_y, return_counts=True)\n",
    "dict(zip(unique, counts))\n",
    "\n",
    "freq = [np.sum(counts)/j for j in counts]\n",
    "weightsSeg = [f/np.sum(freq) for f in freq]\n",
    "print(weightsSeg)\n",
    "\n",
    "def dice_coef_anti(y_true, y_pred):\n",
    "    smooth = 1.  # to avoid zero division\n",
    "    y_true_anti = y_true[:,:,1]\n",
    "    y_pred_anti = y_pred[:,:,1]\n",
    "    intersection_anti = K.sum(y_true_anti * y_pred_anti)\n",
    "    return (2 * intersection_anti + smooth) / (K.sum(y_true_anti)+ K.sum(y_pred_anti) + smooth)\n",
    "\n",
    "def dice_coef_cyc(y_true, y_pred):\n",
    "    smooth = 1.  # to avoid zero division\n",
    "    y_true_cyc = y_true[:,:,2]\n",
    "    y_pred_cyc = y_pred[:,:,2]\n",
    "    intersection_cyc = K.sum(y_true_cyc * y_pred_cyc)\n",
    "    return (2 * intersection_cyc + smooth) / (K.sum(y_true_cyc) + K.sum(y_pred_cyc) + smooth)\n",
    "\n",
    "def dice_coef_nn(y_true, y_pred):\n",
    "    smooth = 1.  # to avoid zero division\n",
    "    y_true_nn = y_true[:,:,0]\n",
    "    y_pred_nn = y_pred[:,:,0]\n",
    "    intersection_nn = K.sum(y_true_nn * y_pred_nn)\n",
    "    return (2 * intersection_nn + smooth) / (K.sum(y_true_nn) + K.sum(y_pred_nn) + smooth)\n",
    "    \n",
    "def mean_dice_coef(y_true, y_pred):\n",
    "    return (dice_coef_anti(y_true, y_pred) + dice_coef_cyc(y_true, y_pred) + dice_coef_nn(y_true, y_pred))/3.\n",
    "\n",
    "def weighted_mean_dice_coef(y_true, y_pred):\n",
    "    #return (weightsSeg[2]*dice_coef_anti(y_true, y_pred) + weightsSeg[1]*dice_coef_cyc(y_true, y_pred) + weightsSeg[0]*dice_coef_nn(y_true, y_pred))\n",
    "    return (weightsSeg[2]*dice_coef_anti(y_true, y_pred) + weightsSeg[1]*dice_coef_cyc(y_true, y_pred) + weightsSeg[0]*dice_coef_nn(y_true, y_pred))\n",
    "      \n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - weighted_mean_dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input: (1752, 256, 256)\n",
      "val_input: (438, 256, 256)\n",
      "Size of each batch:  (16, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split our img paths into a training and a validation set\n",
    "split = 0.2\n",
    "train_samples = int((1-split)*total_samples)\n",
    "#same seed must be used\n",
    "random.Random(0).shuffle(data_x)\n",
    "random.Random(0).shuffle(data_y)\n",
    "train_input = data_x[0:train_samples]\n",
    "train_target = data_y[0:train_samples]\n",
    "val_input = data_x[train_samples:total_samples]\n",
    "val_target = data_y[train_samples:total_samples]\n",
    "\n",
    "print(\"train_input:\", train_input.shape)\n",
    "print(\"val_input:\", val_input.shape)\n",
    "\n",
    "# Instantiate data Sequences for each split\n",
    "train_gen = plain_net_eddy(batch_size, img_size, train_input, train_target)\n",
    "val_gen = plain_net_eddy(batch_size, img_size, val_input, val_target)\n",
    "print(\"Size of each batch: \",train_gen[1][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "109/109 [==============================] - 430s 4s/step - loss: 0.8448 - categorical_accuracy: 0.6110 - mean_dice_coef: 0.2984 - weighted_mean_dice_coef: 0.1552 - val_loss: 0.8931 - val_categorical_accuracy: 0.8885 - val_mean_dice_coef: 0.2852 - val_weighted_mean_dice_coef: 0.1069 - lr: 0.0010\n",
      "Epoch 2/90\n",
      "109/109 [==============================] - 426s 4s/step - loss: 0.6986 - categorical_accuracy: 0.7342 - mean_dice_coef: 0.4557 - weighted_mean_dice_coef: 0.3014 - val_loss: 0.9385 - val_categorical_accuracy: 0.8885 - val_mean_dice_coef: 0.3293 - val_weighted_mean_dice_coef: 0.0615 - lr: 0.0010\n",
      "Epoch 3/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.5515 - categorical_accuracy: 0.8709 - mean_dice_coef: 0.5947 - weighted_mean_dice_coef: 0.4485 - val_loss: 0.9690 - val_categorical_accuracy: 0.8885 - val_mean_dice_coef: 0.3153 - val_weighted_mean_dice_coef: 0.0310 - lr: 0.0010\n",
      "Epoch 4/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.4775 - categorical_accuracy: 0.8997 - mean_dice_coef: 0.6541 - weighted_mean_dice_coef: 0.5225 - val_loss: 0.9628 - val_categorical_accuracy: 0.8887 - val_mean_dice_coef: 0.3203 - val_weighted_mean_dice_coef: 0.0372 - lr: 0.0010\n",
      "Epoch 5/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.4440 - categorical_accuracy: 0.9090 - mean_dice_coef: 0.6792 - weighted_mean_dice_coef: 0.5560 - val_loss: 0.8093 - val_categorical_accuracy: 0.8934 - val_mean_dice_coef: 0.4282 - val_weighted_mean_dice_coef: 0.1907 - lr: 0.0010\n",
      "Epoch 6/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.4256 - categorical_accuracy: 0.9133 - mean_dice_coef: 0.6927 - weighted_mean_dice_coef: 0.5744 - val_loss: 0.7407 - val_categorical_accuracy: 0.8983 - val_mean_dice_coef: 0.4768 - val_weighted_mean_dice_coef: 0.2593 - lr: 0.0010\n",
      "Epoch 7/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.4076 - categorical_accuracy: 0.9177 - mean_dice_coef: 0.7060 - weighted_mean_dice_coef: 0.5924 - val_loss: 0.6054 - val_categorical_accuracy: 0.9069 - val_mean_dice_coef: 0.5701 - val_weighted_mean_dice_coef: 0.3946 - lr: 0.0010\n",
      "Epoch 8/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3982 - categorical_accuracy: 0.9197 - mean_dice_coef: 0.7129 - weighted_mean_dice_coef: 0.6018 - val_loss: 0.5716 - val_categorical_accuracy: 0.9086 - val_mean_dice_coef: 0.5928 - val_weighted_mean_dice_coef: 0.4284 - lr: 0.0010\n",
      "Epoch 9/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3877 - categorical_accuracy: 0.9219 - mean_dice_coef: 0.7205 - weighted_mean_dice_coef: 0.6123 - val_loss: 0.6042 - val_categorical_accuracy: 0.9070 - val_mean_dice_coef: 0.5692 - val_weighted_mean_dice_coef: 0.3958 - lr: 0.0010\n",
      "Epoch 10/90\n",
      "109/109 [==============================] - 426s 4s/step - loss: 0.3805 - categorical_accuracy: 0.9235 - mean_dice_coef: 0.7258 - weighted_mean_dice_coef: 0.6195 - val_loss: 0.6047 - val_categorical_accuracy: 0.9060 - val_mean_dice_coef: 0.5694 - val_weighted_mean_dice_coef: 0.3953 - lr: 0.0010\n",
      "Epoch 11/90\n",
      "109/109 [==============================] - 426s 4s/step - loss: 0.3733 - categorical_accuracy: 0.9249 - mean_dice_coef: 0.7310 - weighted_mean_dice_coef: 0.6267 - val_loss: 0.4749 - val_categorical_accuracy: 0.9128 - val_mean_dice_coef: 0.6591 - val_weighted_mean_dice_coef: 0.5251 - lr: 0.0010\n",
      "Epoch 12/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3653 - categorical_accuracy: 0.9265 - mean_dice_coef: 0.7367 - weighted_mean_dice_coef: 0.6347 - val_loss: 0.4878 - val_categorical_accuracy: 0.9156 - val_mean_dice_coef: 0.6515 - val_weighted_mean_dice_coef: 0.5122 - lr: 0.0010\n",
      "Epoch 13/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3590 - categorical_accuracy: 0.9280 - mean_dice_coef: 0.7413 - weighted_mean_dice_coef: 0.6410 - val_loss: 0.5429 - val_categorical_accuracy: 0.9071 - val_mean_dice_coef: 0.6130 - val_weighted_mean_dice_coef: 0.4571 - lr: 0.0010\n",
      "Epoch 14/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3571 - categorical_accuracy: 0.9282 - mean_dice_coef: 0.7427 - weighted_mean_dice_coef: 0.6429 - val_loss: 0.4756 - val_categorical_accuracy: 0.9046 - val_mean_dice_coef: 0.6583 - val_weighted_mean_dice_coef: 0.5244 - lr: 0.0010\n",
      "Epoch 15/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3531 - categorical_accuracy: 0.9289 - mean_dice_coef: 0.7456 - weighted_mean_dice_coef: 0.6469 - val_loss: 0.4721 - val_categorical_accuracy: 0.9076 - val_mean_dice_coef: 0.6612 - val_weighted_mean_dice_coef: 0.5279 - lr: 0.0010\n",
      "Epoch 16/90\n",
      "109/109 [==============================] - 426s 4s/step - loss: 0.3467 - categorical_accuracy: 0.9302 - mean_dice_coef: 0.7501 - weighted_mean_dice_coef: 0.6533 - val_loss: 0.4476 - val_categorical_accuracy: 0.9127 - val_mean_dice_coef: 0.6785 - val_weighted_mean_dice_coef: 0.5524 - lr: 0.0010\n",
      "Epoch 17/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3449 - categorical_accuracy: 0.9306 - mean_dice_coef: 0.7515 - weighted_mean_dice_coef: 0.6551 - val_loss: 0.4428 - val_categorical_accuracy: 0.9153 - val_mean_dice_coef: 0.6824 - val_weighted_mean_dice_coef: 0.5572 - lr: 0.0010\n",
      "Epoch 18/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3436 - categorical_accuracy: 0.9309 - mean_dice_coef: 0.7525 - weighted_mean_dice_coef: 0.6564 - val_loss: 0.4678 - val_categorical_accuracy: 0.9073 - val_mean_dice_coef: 0.6639 - val_weighted_mean_dice_coef: 0.5322 - lr: 0.0010\n",
      "Epoch 19/90\n",
      "109/109 [==============================] - 426s 4s/step - loss: 0.3372 - categorical_accuracy: 0.9322 - mean_dice_coef: 0.7570 - weighted_mean_dice_coef: 0.6628 - val_loss: 0.4945 - val_categorical_accuracy: 0.9109 - val_mean_dice_coef: 0.6469 - val_weighted_mean_dice_coef: 0.5055 - lr: 0.0010\n",
      "Epoch 20/90\n",
      "109/109 [==============================] - 426s 4s/step - loss: 0.3361 - categorical_accuracy: 0.9325 - mean_dice_coef: 0.7578 - weighted_mean_dice_coef: 0.6639 - val_loss: 0.4606 - val_categorical_accuracy: 0.9171 - val_mean_dice_coef: 0.6712 - val_weighted_mean_dice_coef: 0.5394 - lr: 0.0010\n",
      "Epoch 21/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3324 - categorical_accuracy: 0.9331 - mean_dice_coef: 0.7605 - weighted_mean_dice_coef: 0.6676 - val_loss: 0.4440 - val_categorical_accuracy: 0.9144 - val_mean_dice_coef: 0.6819 - val_weighted_mean_dice_coef: 0.5560 - lr: 0.0010\n",
      "Epoch 22/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3313 - categorical_accuracy: 0.9333 - mean_dice_coef: 0.7612 - weighted_mean_dice_coef: 0.6687 - val_loss: 0.5183 - val_categorical_accuracy: 0.9053 - val_mean_dice_coef: 0.6289 - val_weighted_mean_dice_coef: 0.4817 - lr: 0.0010\n",
      "Epoch 23/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3295 - categorical_accuracy: 0.9337 - mean_dice_coef: 0.7625 - weighted_mean_dice_coef: 0.6705 - val_loss: 0.4856 - val_categorical_accuracy: 0.9126 - val_mean_dice_coef: 0.6525 - val_weighted_mean_dice_coef: 0.5144 - lr: 0.0010\n",
      "Epoch 24/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3262 - categorical_accuracy: 0.9345 - mean_dice_coef: 0.7649 - weighted_mean_dice_coef: 0.6738 - val_loss: 0.4135 - val_categorical_accuracy: 0.9158 - val_mean_dice_coef: 0.7025 - val_weighted_mean_dice_coef: 0.5865 - lr: 0.0010\n",
      "Epoch 25/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3250 - categorical_accuracy: 0.9345 - mean_dice_coef: 0.7657 - weighted_mean_dice_coef: 0.6750 - val_loss: 0.4318 - val_categorical_accuracy: 0.9108 - val_mean_dice_coef: 0.6885 - val_weighted_mean_dice_coef: 0.5682 - lr: 0.0010\n",
      "Epoch 26/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3240 - categorical_accuracy: 0.9347 - mean_dice_coef: 0.7665 - weighted_mean_dice_coef: 0.6760 - val_loss: 0.4644 - val_categorical_accuracy: 0.9008 - val_mean_dice_coef: 0.6638 - val_weighted_mean_dice_coef: 0.5356 - lr: 0.0010\n",
      "Epoch 27/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.3231 - categorical_accuracy: 0.9350 - mean_dice_coef: 0.7672 - weighted_mean_dice_coef: 0.6769 - val_loss: 0.4441 - val_categorical_accuracy: 0.9079 - val_mean_dice_coef: 0.6792 - val_weighted_mean_dice_coef: 0.5559 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.3183 - categorical_accuracy: 0.9359 - mean_dice_coef: 0.7706 - weighted_mean_dice_coef: 0.6817 - val_loss: 0.3896 - val_categorical_accuracy: 0.9173 - val_mean_dice_coef: 0.7185 - val_weighted_mean_dice_coef: 0.6104 - lr: 0.0010\n",
      "Epoch 29/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.3156 - categorical_accuracy: 0.9364 - mean_dice_coef: 0.7725 - weighted_mean_dice_coef: 0.6844 - val_loss: 0.4278 - val_categorical_accuracy: 0.9192 - val_mean_dice_coef: 0.6938 - val_weighted_mean_dice_coef: 0.5722 - lr: 0.0010\n",
      "Epoch 30/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.3175 - categorical_accuracy: 0.9361 - mean_dice_coef: 0.7712 - weighted_mean_dice_coef: 0.6825 - val_loss: 0.4878 - val_categorical_accuracy: 0.9072 - val_mean_dice_coef: 0.6499 - val_weighted_mean_dice_coef: 0.5122 - lr: 0.0010\n",
      "Epoch 31/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.3182 - categorical_accuracy: 0.9359 - mean_dice_coef: 0.7707 - weighted_mean_dice_coef: 0.6818 - val_loss: 0.4800 - val_categorical_accuracy: 0.9069 - val_mean_dice_coef: 0.6553 - val_weighted_mean_dice_coef: 0.5200 - lr: 0.0010\n",
      "Epoch 32/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.3125 - categorical_accuracy: 0.9372 - mean_dice_coef: 0.7748 - weighted_mean_dice_coef: 0.6875 - val_loss: 0.4962 - val_categorical_accuracy: 0.9084 - val_mean_dice_coef: 0.6453 - val_weighted_mean_dice_coef: 0.5038 - lr: 0.0010\n",
      "Epoch 33/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.3123 - categorical_accuracy: 0.9372 - mean_dice_coef: 0.7750 - weighted_mean_dice_coef: 0.6877 - val_loss: 0.4667 - val_categorical_accuracy: 0.9157 - val_mean_dice_coef: 0.6663 - val_weighted_mean_dice_coef: 0.5333 - lr: 0.0010\n",
      "Epoch 34/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.3100 - categorical_accuracy: 0.9375 - mean_dice_coef: 0.7765 - weighted_mean_dice_coef: 0.6900 - val_loss: 0.4059 - val_categorical_accuracy: 0.9222 - val_mean_dice_coef: 0.7083 - val_weighted_mean_dice_coef: 0.5941 - lr: 0.0010\n",
      "Epoch 35/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.3123 - categorical_accuracy: 0.9371 - mean_dice_coef: 0.7749 - weighted_mean_dice_coef: 0.6877 - val_loss: 0.4430 - val_categorical_accuracy: 0.9123 - val_mean_dice_coef: 0.6815 - val_weighted_mean_dice_coef: 0.5570 - lr: 0.0010\n",
      "Epoch 36/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3098 - categorical_accuracy: 0.9375 - mean_dice_coef: 0.7767 - weighted_mean_dice_coef: 0.6902 - val_loss: 0.4775 - val_categorical_accuracy: 0.9065 - val_mean_dice_coef: 0.6578 - val_weighted_mean_dice_coef: 0.5225 - lr: 0.0010\n",
      "Epoch 37/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3070 - categorical_accuracy: 0.9382 - mean_dice_coef: 0.7787 - weighted_mean_dice_coef: 0.6930 - val_loss: 0.4579 - val_categorical_accuracy: 0.9063 - val_mean_dice_coef: 0.6706 - val_weighted_mean_dice_coef: 0.5421 - lr: 0.0010\n",
      "Epoch 38/90\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3063 - categorical_accuracy: 0.9383 - mean_dice_coef: 0.7792 - weighted_mean_dice_coef: 0.6937\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3063 - categorical_accuracy: 0.9383 - mean_dice_coef: 0.7792 - weighted_mean_dice_coef: 0.6937 - val_loss: 0.4369 - val_categorical_accuracy: 0.9180 - val_mean_dice_coef: 0.6881 - val_weighted_mean_dice_coef: 0.5631 - lr: 0.0010\n",
      "Epoch 39/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.3009 - categorical_accuracy: 0.9393 - mean_dice_coef: 0.7831 - weighted_mean_dice_coef: 0.6991 - val_loss: 0.4303 - val_categorical_accuracy: 0.9116 - val_mean_dice_coef: 0.6902 - val_weighted_mean_dice_coef: 0.5697 - lr: 5.0000e-04\n",
      "Epoch 40/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2986 - categorical_accuracy: 0.9400 - mean_dice_coef: 0.7848 - weighted_mean_dice_coef: 0.7014 - val_loss: 0.4492 - val_categorical_accuracy: 0.9191 - val_mean_dice_coef: 0.6790 - val_weighted_mean_dice_coef: 0.5508 - lr: 5.0000e-04\n",
      "Epoch 41/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2988 - categorical_accuracy: 0.9400 - mean_dice_coef: 0.7847 - weighted_mean_dice_coef: 0.7012 - val_loss: 0.4168 - val_categorical_accuracy: 0.9156 - val_mean_dice_coef: 0.7000 - val_weighted_mean_dice_coef: 0.5832 - lr: 5.0000e-04\n",
      "Epoch 42/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2976 - categorical_accuracy: 0.9401 - mean_dice_coef: 0.7855 - weighted_mean_dice_coef: 0.7024 - val_loss: 0.4185 - val_categorical_accuracy: 0.9200 - val_mean_dice_coef: 0.7006 - val_weighted_mean_dice_coef: 0.5815 - lr: 5.0000e-04\n",
      "Epoch 43/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2976 - categorical_accuracy: 0.9402 - mean_dice_coef: 0.7855 - weighted_mean_dice_coef: 0.7024 - val_loss: 0.4368 - val_categorical_accuracy: 0.9186 - val_mean_dice_coef: 0.6874 - val_weighted_mean_dice_coef: 0.5632 - lr: 5.0000e-04\n",
      "Epoch 44/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2963 - categorical_accuracy: 0.9402 - mean_dice_coef: 0.7864 - weighted_mean_dice_coef: 0.7037 - val_loss: 0.4027 - val_categorical_accuracy: 0.9217 - val_mean_dice_coef: 0.7112 - val_weighted_mean_dice_coef: 0.5973 - lr: 5.0000e-04\n",
      "Epoch 45/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2980 - categorical_accuracy: 0.9400 - mean_dice_coef: 0.7852 - weighted_mean_dice_coef: 0.7020 - val_loss: 0.3945 - val_categorical_accuracy: 0.9184 - val_mean_dice_coef: 0.7161 - val_weighted_mean_dice_coef: 0.6055 - lr: 5.0000e-04\n",
      "Epoch 46/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.2947 - categorical_accuracy: 0.9407 - mean_dice_coef: 0.7876 - weighted_mean_dice_coef: 0.7053 - val_loss: 0.4310 - val_categorical_accuracy: 0.9150 - val_mean_dice_coef: 0.6905 - val_weighted_mean_dice_coef: 0.5690 - lr: 5.0000e-04\n",
      "Epoch 47/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.2965 - categorical_accuracy: 0.9402 - mean_dice_coef: 0.7863 - weighted_mean_dice_coef: 0.7035 - val_loss: 0.4049 - val_categorical_accuracy: 0.9176 - val_mean_dice_coef: 0.7086 - val_weighted_mean_dice_coef: 0.5951 - lr: 5.0000e-04\n",
      "Epoch 48/90\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2951 - categorical_accuracy: 0.9406 - mean_dice_coef: 0.7874 - weighted_mean_dice_coef: 0.7049\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2951 - categorical_accuracy: 0.9406 - mean_dice_coef: 0.7874 - weighted_mean_dice_coef: 0.7049 - val_loss: 0.4032 - val_categorical_accuracy: 0.9226 - val_mean_dice_coef: 0.7112 - val_weighted_mean_dice_coef: 0.5968 - lr: 5.0000e-04\n",
      "Epoch 49/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2918 - categorical_accuracy: 0.9414 - mean_dice_coef: 0.7897 - weighted_mean_dice_coef: 0.7082 - val_loss: 0.3952 - val_categorical_accuracy: 0.9218 - val_mean_dice_coef: 0.7164 - val_weighted_mean_dice_coef: 0.6048 - lr: 2.5000e-04\n",
      "Epoch 50/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.2905 - categorical_accuracy: 0.9414 - mean_dice_coef: 0.7906 - weighted_mean_dice_coef: 0.7095 - val_loss: 0.3896 - val_categorical_accuracy: 0.9223 - val_mean_dice_coef: 0.7204 - val_weighted_mean_dice_coef: 0.6104 - lr: 2.5000e-04\n",
      "Epoch 51/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2909 - categorical_accuracy: 0.9415 - mean_dice_coef: 0.7904 - weighted_mean_dice_coef: 0.7091 - val_loss: 0.3787 - val_categorical_accuracy: 0.9254 - val_mean_dice_coef: 0.7280 - val_weighted_mean_dice_coef: 0.6213 - lr: 2.5000e-04\n",
      "Epoch 52/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2908 - categorical_accuracy: 0.9415 - mean_dice_coef: 0.7904 - weighted_mean_dice_coef: 0.7092 - val_loss: 0.3774 - val_categorical_accuracy: 0.9247 - val_mean_dice_coef: 0.7289 - val_weighted_mean_dice_coef: 0.6226 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.2900 - categorical_accuracy: 0.9417 - mean_dice_coef: 0.7910 - weighted_mean_dice_coef: 0.7100 - val_loss: 0.4029 - val_categorical_accuracy: 0.9209 - val_mean_dice_coef: 0.7111 - val_weighted_mean_dice_coef: 0.5971 - lr: 2.5000e-04\n",
      "Epoch 54/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.2896 - categorical_accuracy: 0.9418 - mean_dice_coef: 0.7913 - weighted_mean_dice_coef: 0.7104 - val_loss: 0.3940 - val_categorical_accuracy: 0.9242 - val_mean_dice_coef: 0.7179 - val_weighted_mean_dice_coef: 0.6060 - lr: 2.5000e-04\n",
      "Epoch 55/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2893 - categorical_accuracy: 0.9418 - mean_dice_coef: 0.7915 - weighted_mean_dice_coef: 0.7107 - val_loss: 0.4223 - val_categorical_accuracy: 0.9219 - val_mean_dice_coef: 0.6977 - val_weighted_mean_dice_coef: 0.5777 - lr: 2.5000e-04\n",
      "Epoch 56/90\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.2901 - categorical_accuracy: 0.9416 - mean_dice_coef: 0.7909 - weighted_mean_dice_coef: 0.7099 - val_loss: 0.4048 - val_categorical_accuracy: 0.9225 - val_mean_dice_coef: 0.7102 - val_weighted_mean_dice_coef: 0.5952 - lr: 2.5000e-04\n",
      "Epoch 57/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2895 - categorical_accuracy: 0.9418 - mean_dice_coef: 0.7914 - weighted_mean_dice_coef: 0.7105 - val_loss: 0.3933 - val_categorical_accuracy: 0.9226 - val_mean_dice_coef: 0.7179 - val_weighted_mean_dice_coef: 0.6067 - lr: 2.5000e-04\n",
      "Epoch 58/90\n",
      "109/109 [==============================] - 425s 4s/step - loss: 0.2885 - categorical_accuracy: 0.9420 - mean_dice_coef: 0.7921 - weighted_mean_dice_coef: 0.7115 - val_loss: 0.3855 - val_categorical_accuracy: 0.9250 - val_mean_dice_coef: 0.7237 - val_weighted_mean_dice_coef: 0.6145 - lr: 2.5000e-04\n",
      "Epoch 59/90\n",
      "102/109 [===========================>..] - ETA: 25s - loss: 0.2896 - categorical_accuracy: 0.9416 - mean_dice_coef: 0.7912 - weighted_mean_dice_coef: 0.7104"
     ]
    }
   ],
   "source": [
    "file_path_save = \"/albedo/home/ssunar/CNN_eddy_detection/for_paper/unet_trained/south_atlantic\"\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss=dice_coef_loss, metrics=['categorical_accuracy', mean_dice_coef, weighted_mean_dice_coef])\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(file_path_save, save_best_only=True , monitor='val_loss',save_weights_only=True, save_freq=\"epoch\"),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1, mode='auto', min_delta=1e-30, min_lr=1e-30)]\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch.\n",
    "history = model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks, shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_path = \"/albedo/home/ssunar/CNN_eddy_detection/for_paper/unet_trained/south_atlantic\"\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.semilogy(model.history.history['loss'])\n",
    "plt.semilogy(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right');\n",
    "plt.savefig(dir_path + \"loss_graph.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "val_gen = plain_net_eddy(batch_size, img_size, val_input, val_target)\n",
    "val_preds = model.predict(val_gen)\n",
    "print(val_preds.shape)\n",
    "\n",
    "end = time.time()\n",
    "time_per_img = (end - start)/438\n",
    "print(\"Time Per image:\",time_per_img)\n",
    "print(\"Time for 1 year eqv:\",time_per_img*365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_gen = plain_net_eddy(batch_size, img_size, val_input, val_target)\n",
    "# mask = np.expand_dims(val_preds, axis=-1)\n",
    "val_gen = data_x[10]\n",
    "val_gen = np.reshape(val_gen,(1,img_size[0],img_size[1],1))\n",
    "print(val_gen.shape)\n",
    "val_preds = model.predict(val_gen)\n",
    "print(val_preds.shape)\n",
    "mask = np.argmax(np.reshape(val_preds[0],(1,img_size[1],img_size[0],3)), axis=-1)\n",
    "mask = np.reshape(mask,(img_size[0],img_size[1]))\n",
    "print(classification_report(np.reshape(data_y[10],(65536)),np.reshape(mask,(65536))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing the prediction of one image of the validation set\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(mask.T, cmap='viridis')\n",
    "plt.colorbar(extend='both', fraction=0.042, pad=0.04)\n",
    "plt.axis('off')\n",
    "plt.title('Result Segmentation');\n",
    "plt.savefig(dir_path + \"prediction.png\", dpi = 300)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(data_y[10].T, cmap='viridis')\n",
    "plt.colorbar(extend='both', fraction=0.042, pad=0.04)\n",
    "plt.axis('off')\n",
    "plt.title('Groundtruth Segmentation');\n",
    "plt.savefig(dir_path + \"groundtruth.png\", dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eddy-tracking",
   "language": "python",
   "name": "eddy-tracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
